---
title: Total quarterly production of cement in Australia (in millions of tonnes),
  first quarter 1958 - fourth quarter 2015 (n=232).
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE,include=FALSE}
library(forecast)
```

```{r}
data = read.table("tutoria15681581.txt")
data = data[, 1]  
z = ts(data, start=c(1958,1), frequency=4)
```

```{r, echo=FALSE}
plot(data, type='l', axes=FALSE, xlab="", ylab='cement (in millions of tons)', main='Total quarterly production of cement in Australia (1958- 2015)')
box()
axis(1, at=c(seq(0,232,by=24),232), labels=c(seq(1958,2015,by=6),2015))
axis(2, at=seq(0,3,by=0.5),labels=seq(0,3,by=0.5))  
```

comentar que vemos trend y seasonal y varianza distinta

```{r}
ggseasonplot(z, main='Seasonal plot: Total production of cement')

```

la periodicidad es efectivamente 4

# box cox transformation

```{r, message=FALSE,include=FALSE}
# x: observed time series
# n.tilde: number of observations per group

n.tilde = 4

Plot.var=function(x,n.tilde)  
{
  A.temp=matrix(x,ncol=n.tilde,byrow=T)     # Each row correspond to a group of n.tilde consecutive observations 
  xbar.vec=apply(A.temp,1,mean)       # vector of means 
  s.vec=sqrt(apply(A.temp,1,var))     # vector of standard deviations 
  plot(log(xbar.vec),log(s.vec),xlab="log(mean)",ylab="log(standard deviation)",main=paste("Number of observations per group:",n.tilde),type="p")
}

#summary(lm(log(apply(matrix(z,ncol=n.tilde,byrow=T),1,mean)))~log(sqrt(apply(matrix(z,ncol=n.tilde,byrow=T),1,var))))

BoxCox=function(x,n.tilde)
{
  A.temp=matrix(x,ncol=n.tilde,byrow=T)    # Each row correspond to a group of n.tilde consecutive observations 
  xbar.vec=apply(A.temp,1,mean)      # vector of means 
  s.vec=sqrt(apply(A.temp,1,var))    # vector of standard deviations 
  lambda=1-lm(log(s.vec)~log(xbar.vec))$coefficients[2]
  yt=(x^lambda-1)/lambda
  lambda1=round(lambda,2)
  ts.plot(yt,xlab="",ylab="",main=paste("Transformed series obtained using the Box-Cox transformation with lambda=",lambda1),type="l")
}

BoxCox.out=function(x,n.tilde)
{
  A.temp=matrix(x,ncol=n.tilde,byrow=T)   
  xbar.vec=apply(A.temp,1,mean)       
  s.vec=sqrt(apply(A.temp,1,var))
  lambda=1-lm(log(s.vec)~log(xbar.vec))$coefficients[2]
  yt=(x^lambda-1)/lambda
  #return(list(yt,lambda))
  return(yt)
}

```

```{r}
Plot.var(z, n.tilde)
```

la relacion es lineal para hacer la transformacion

```{r}
BoxCox(data, n.tilde)

```

Transformed series obtained using the Box-Cox transformation with lambda=-0.13
now the variance is constant as we can see

```{r}
X.tilde = BoxCox.out(data, n.tilde)
```

```{r}
Acf(X.tilde,main="ACF of the transformed series",xlab="Lag",ylab="ACF")
```

decreases linearly slowly 
we apply differencing operator

```{r}
Wt.1 = diff(X.tilde, lag=1, differences=1)
ts.plot(Wt.1, main='First difference of the transformed series', ylab='', xlab='')
```

```{r}
Acf(Wt.1, main="ACF of the first difference of the transformed series",xlab="Lag",ylab="ACF")

```

as we see acf non zero on seasonal lags, we apply seasonal differencing operator (s=4)

```{r}
Wt.2 = diff(Wt.1, lag=4, differences = 1)

plot(Wt.2,type='l', main='Transformed series after one regular difference and one seasonal difference', ylab='', xlab='')

```

```{r}
ggseasonplot(ts(Wt.2,frequency=4))
```

con ggseasonal ver estacionariedad

```{r}
mean(Wt.2)
```

the mean is 0

```{r, echo=FALSE}
acf.2=Acf(Wt.2, 58, main='ACF of the time series after one regular and one seasonal differences')
```

```{r}
pacf.2=Pacf(Wt.2)
```


Thus, as a result of the identification step we have identified the following class of models for the  "original'' series $\{{\tilde W}_{t}\}$

-   $M_{1}$: ARIMA(4,1,0)$_{4}$x(1,1,1)
-   $M_{2}$: ARIMA(4,1,0)$_{4}$x(2,1,1)
-   $M_{3}$: ARIMA(4,1,0)$_{4}$x(1,1,0)
-   $M_{4}$: ARIMA(4,1,0)$_{4}$x(2,1,0)
-   $M_{5}$: ARIMA(2,1,2)$_{4}$x(2,1,0)
-   $M_{6}$: ARIMA(2,1,2)$_{4}$x(2,1,1)
-   $M_{7}$: ARIMA(2,1,0)$_{4}$x(2,1,0)
-   $M_{8}$: ARIMA(2,1,0)$_{4}$x(2,1,1)
-   $M_{9}$: ARIMA(2,1,2)$_{4}$x(0,1,1)
-   $M_{10}$: ARIMA(2,1,0)$_{4}$x(0,1,1)
-   $M_{11}$: ARIMA(4,1,0)$_{4}$x(0,1,1)

### Maximum Likelihood estimation

The maximum likelihood estimation of the parameters of an ARIMA model can be computed using the *Arima* function (*forecast* package)

```{r}
mod1 = Arima(data,order=c(1,1,1),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)
mod2 = Arima(data,order=c(2,1,1),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)
mod3 = Arima(data,order=c(1,1,0),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)
mod4 = Arima(data,order=c(2,1,0),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)
mod5 = Arima(data,order=c(2,1,0),seasonal=list(order=c(2,1,2),period=4),lambda=-0.13)
mod6 = Arima(data,order=c(2,1,1),seasonal=list(order=c(2,1,2),period=4),lambda=-0.13)
mod7 = Arima(data,order=c(2,1,0),seasonal=list(order=c(2,1,0),period=4),lambda=-0.13)
mod8 = Arima(data,order=c(2,1,1),seasonal=list(order=c(2,1,0),period=4),lambda=-0.13)
mod9 = Arima(data,order=c(0,1,1),seasonal=list(order=c(2,1,2),period=4),lambda=-0.13)
mod10 = Arima(data,order=c(0,1,1),seasonal=list(order=c(2,1,0),period=4),lambda=-0.13)
mod11 = Arima(data,order=c(0,1,1),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)

```

### Model Selection

The *Arima* function also provides the value of the AIC and BIC criterion

```{r}
AIC.BIC=rbind(c(mod1$"aic",mod1$"aicc",mod1$"bic"),
              c(mod2$"aic",mod2$"aicc",mod2$"bic"),
              c(mod3$"aic",mod3$"aicc",mod3$"bic"),
              c(mod4$"aic",mod4$"aicc",mod4$"bic"),
              c(mod5$"aic",mod5$"aicc",mod5$"bic"),
              c(mod6$"aic",mod6$"aicc",mod6$"bic"),
              c(mod7$"aic",mod7$"aicc",mod7$"bic"),
              c(mod8$"aic",mod8$"aicc",mod8$"bic"),
              c(mod9$"aic",mod9$"aicc",mod9$"bic"),
              c(mod10$"aic",mod10$"aicc",mod10$"bic"),
              c(mod11$"aic",mod11$"aicc",mod11$"bic"))

dimnames(AIC.BIC)=list(c("Model 1","Model 2", "Model 3", 'Model 4', "Model 5","Model 6", "Model 7", 'Model 8', 'Model 9', 'Model 10', 'Model 11'),c("AIC","AICc","BIC"))
AIC.BIC
```

As an additional criterion for model selection we consider cross-validation

```{r}
n.min = 100  # minimal sample size  required to estimate a model
n.data=length(data)
MSE.vec1=numeric(n.data-n.min) # Mean Squared Error model 1
MAE.vec1=numeric(n.data-n.min) # Mean Absolute Error model 1
MSE.vec2=numeric(n.data-n.min) # Mean Squared Error model 2
MAE.vec2=numeric(n.data-n.min) # Mean Absolute Error model 2
MSE.vec3=numeric(n.data-n.min) # Mean Squared Error model 3
MAE.vec3=numeric(n.data-n.min) # Mean Absolute Error model 3
MSE.vec4=numeric(n.data-n.min) # Mean Squared Error model 4
MAE.vec4=numeric(n.data-n.min) # Mean Absolute Error model 4
MSE.vec5=numeric(n.data-n.min) # Mean Squared Error model 5
MAE.vec5=numeric(n.data-n.min) # Mean Absolute Error model 5
MSE.vec6=numeric(n.data-n.min) # Mean Squared Error model 6
MAE.vec6=numeric(n.data-n.min) # Mean Absolute Error model 6
MSE.vec7=numeric(n.data-n.min) # Mean Squared Error model 7
MAE.vec7=numeric(n.data-n.min) # Mean Absolute Error model 7
MSE.vec8=numeric(n.data-n.min) # Mean Squared Error model 8
MAE.vec8=numeric(n.data-n.min) # Mean Absolute Error model 8
MSE.vec9=numeric(n.data-n.min) 
MAE.vec9=numeric(n.data-n.min) 
MSE.vec10=numeric(n.data-n.min) 
MAE.vec10=numeric(n.data-n.min) 
MSE.vec11=numeric(n.data-n.min) 
MAE.vec11=numeric(n.data-n.min) 

for (k in 1:(n.data-n.min))
{
  fit.mod1=Arima(data[1:(n.min+k-1)],order=c(1,1,1),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)   
  forcast.mod1 <- forecast(fit.mod1, h=1)[['mean']]
  fit.mod2=Arima(data[1:(n.min+k-1)],order=c(2,1,1),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)
  forcast.mod2 <- forecast(fit.mod2, h=1)[['mean']]
  fit.mod3=Arima(data[1:(n.min+k-1)],order=c(1,1,0),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)
  forcast.mod3 <- forecast(fit.mod3, h=1)[['mean']]
  fit.mod4=Arima(data[1:(n.min+k-1)],order=c(2,1,0),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)
  forcast.mod4 <- forecast(fit.mod4, h=1)[['mean']]
  fit.mod5=Arima(data[1:(n.min+k-1)],order=c(2,1,0),seasonal=list(order=c(2,1,2),period=4),lambda=-0.13)   
  forcast.mod5 <- forecast(fit.mod5, h=1)[['mean']]
  fit.mod6=Arima(data[1:(n.min+k-1)],order=c(2,1,1),seasonal=list(order=c(2,1,2),period=4),lambda=-0.13)
  forcast.mod6 <- forecast(fit.mod6, h=1)[['mean']]
  fit.mod7=Arima(data[1:(n.min+k-1)],order=c(2,1,0),seasonal=list(order=c(2,1,0),period=4),lambda=-0.13)
  forcast.mod7 <- forecast(fit.mod7, h=1)[['mean']]
  fit.mod8=Arima(data[1:(n.min+k-1)],order=c(2,1,1),seasonal=list(order=c(2,1,0),period=4),lambda=-0.13)
  forcast.mod8 <- forecast(fit.mod8, h=1)[['mean']]
  fit.mod9=Arima(data[1:(n.min+k-1)],order=c(0,1,1),seasonal=list(order=c(2,1,2),period=4),lambda=-0.13)
  forcast.mod9 <- forecast(fit.mod9, h=1)[['mean']]
  fit.mod10=Arima(data[1:(n.min+k-1)],order=c(0,1,1),seasonal=list(order=c(2,1,0),period=4),lambda=-0.13)
  forcast.mod10 <- forecast(fit.mod10, h=1)[['mean']]
  fit.mod11=Arima(data[1:(n.min+k-1)],order=c(0,1,1),seasonal=list(order=c(4,1,0),period=4),lambda=-0.13)
  forcast.mod11 <- forecast(fit.mod11, h=1)[['mean']]
  
  MSE.vec1[k]=(data[(n.min+k)]-forcast.mod1)^2
  MAE.vec1[k]=abs(data[(n.min+k)]-forcast.mod1)
  MSE.vec2[k]=(data[(n.min+k)]-forcast.mod2)^2
  MAE.vec2[k]=abs(data[(n.min+k)]-forcast.mod2)
  MSE.vec3[k]=(data[(n.min+k)]-forcast.mod3)^2
  MAE.vec3[k]=abs(data[(n.min+k)]-forcast.mod3)
  MSE.vec4[k]=(data[(n.min+k)]-forcast.mod4)^2
  MAE.vec4[k]=abs(data[(n.min+k)]-forcast.mod4)
  MSE.vec5[k]=(data[(n.min+k)]-forcast.mod5)^2
  MAE.vec5[k]=abs(data[(n.min+k)]-forcast.mod5)
  MSE.vec6[k]=(data[(n.min+k)]-forcast.mod6)^2
  MAE.vec6[k]=abs(data[(n.min+k)]-forcast.mod6)
  MSE.vec7[k]=(data[(n.min+k)]-forcast.mod7)^2
  MAE.vec7[k]=abs(data[(n.min+k)]-forcast.mod7)
  MSE.vec8[k]=(data[(n.min+k)]-forcast.mod8)^2
  MAE.vec8[k]=abs(data[(n.min+k)]-forcast.mod8)
  MSE.vec9[k]=(data[(n.min+k)]-forcast.mod9)^2
  MAE.vec9[k]=abs(data[(n.min+k)]-forcast.mod9)
  MSE.vec10[k]=(data[(n.min+k)]-forcast.mod10)^2
  MAE.vec10[k]=abs(data[(n.min+k)]-forcast.mod10)
  MSE.vec11[k]=(data[(n.min+k)]-forcast.mod11)^2
  MAE.vec11[k]=abs(data[(n.min+k)]-forcast.mod11)
  if (k==104){break}
}

```

```{r}
# Summary Results 

Results.mat=rbind(
  apply(cbind(MSE.vec1,MSE.vec2,MSE.vec3,MSE.vec4,MSE.vec5,MSE.vec6,MSE.vec7,MSE.vec8,MSE.vec9,MSE.vec10,MSE.vec11)[-132,],2,mean),
  apply(cbind(MAE.vec1,MAE.vec2,MAE.vec3,MAE.vec4,MAE.vec5,MAE.vec6,MAE.vec7,MAE.vec8,MAE.vec9,MAE.vec10,MAE.vec11)[-132,],2,mean)
)
dimnames(Results.mat)=list(c("MSE","MAE"),c("Model 1","Model 2", "Model 3", 'Model 4', "Model 5","Model 6", "Model 7", 'Model 8', 'Model 9', 'Model 10', 'Model 11'))

Results.mat
```

nos quedamos con el 4,9 por AIC, BIC, AICc
nos quedamos con 5 por  MSE y MAE

### diagnosis of residuals
```{r, message=FALSE}
require(astsa)
source('Diagnostic.R')
require(portes)
require(nortest)
```

#### Model 4

Test the null hypothesis that the residuals are realizations of an IID noise process.

```{r}
S.ACF(mod4$residuals)
```
```{r}
NonParametric.Tests(mod4$residuals)  
```

For the Ljung.Box test: the time series is seasonal with period s,then lag=min(2s,n/5) = 8

```{r}
My.Ljung.Box(mod4$residuals, 7)
```

Test the null hypothesis that the residuals follow a Normal distribution

```{r}
Check.normality(mod4$residuals)
```

#### Model 5

```{r}

S.ACF(mod5$residuals)
NonParametric.Tests(mod5$residuals)
Check.normality(mod5$residuals)
My.Ljung.Box(mod5$residuals,7)
```

#### Model 9

```{r}

S.ACF(mod9$residuals)
NonParametric.Tests(mod9$residuals)
Check.normality(mod9$residuals)
My.Ljung.Box(mod9$residuals,6)
```

con el S.ACF obtenemos lo mismo para los 3 
con el check normality lo mismo
con el nonparametric lo mismo
con el ljung box nos quedamos con el 4 

### Model fit and prediction

Fit to the original data

```{r}
plot(seq(1,232), data,ylab="cement (in millions of tons)",xlab="",type="l",main="Total quarterly production of cement in Australia (1st quarter 1958 - 4th quarter 2015), n=232",lwd=2)
points(seq(1,232),forecast(mod4)$fitted,col="red",type="l",lwd=2)

```

```{r}
n.data=length(data)
fit.mod4=Arima(data[1:224],order=c(2,1,0),seasonal=list(order=c(4,1,0),period=4 ),lambda=-0.13)   
forcast.mod4 <- forecast(fit.mod4, h=8) #predicciones

```

```{r}
plot(seq(180,232), data[180:232],ylab="cement (in millions of tons)",xlab="",type="l",main="Last fitted values with CI",ylim=c(1.4,3.5))
points(seq(225,232),forcast.mod4$mean,type="l",col="red") # predictions
points(seq(225,232),forcast.mod4$lower[,2],type="l",col="blue") # lower CI
points(seq(225,232),forcast.mod4$upper[,2],type="l",col="blue") # up CI 
```

```{r}
Predic.mod4=forecast(mod4,20)
Predic.mod4
plot(Predic.mod4,50)
```
